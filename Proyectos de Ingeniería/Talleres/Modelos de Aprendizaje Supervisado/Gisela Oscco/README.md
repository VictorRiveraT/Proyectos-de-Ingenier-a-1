**1. PROCEDIMIENTO**

**1.1** Clasificaci贸n Multiclase (Dataset: Salud)

-Carga y feature engineering: Se genera la variable **Stay_Days** a partir de la diferencia entre la fecha de alta y la fecha de admisi贸n.

-Selecci贸n de variables: La variable objetivo ser谩 Test Results. Como predictores se toman todas las columnas excepto las de identificaci贸n (Nombre, Doctor, N煤mero de Habitaci贸n) y las fechas originales.

-Preprocesamiento: Se implementa un **ColumnTransformer** que aplica OneHotEncoder en las variables categ贸ricas y normalizaci贸n en las variables num茅ricas.

-Partici贸n del dataset: Se divide en entrenamiento y prueba con **train_test_split**, manteniendo estratificaci贸n en y, un 20% para test y **random_state=42**.

-Modelo: Se entrena una Regresi贸n Log铆stica con el solver **"saga"**, adecuado para problemas multiclase y datasets con variables codificadas.

Evaluaci贸n: Se obtiene el **classification_report**, exactitud global y matriz de confusi贸n para analizar el desempe帽o.


**1.2** Clasificaci贸n con KNN (Dataset: Datos Clasificados)

**Normalizaci贸n**: Se aplican transformaciones con StandardScaler para que todas las variables est茅n en la misma escala.

**Divisi贸n de datos**: Se separa en entrenamiento y prueba en proporci贸n 50/50, con random_state=101 para asegurar reproducibilidad.

**Modelo inicial**: Se utiliza un clasificador KNN con **n_neighbors=11** como punto de partida.

Optimizaci贸n de hiperpar谩metros: Se emplea **GridSearchCV** probando combinaciones de:

-n煤mero de vecinos (),

-tipo de ponderaci贸n (uniform o distance),

-distancia de Minkowski con  {1,2}, con validaci贸n cruzada de 5 a 10 particiones.

**Curva del codo**: Se analiza la evoluci贸n del error en entrenamiento y validaci贸n con **cross_val_score** para identificar un valor adecuado de .

**M茅tricas finales**: Se reporta la exactitud y la matriz de confusi贸n sobre el conjunto de prueba.

**2. ANALISIS y DISCUSIN**

-Preprocesamiento: El OneHotEncoder permite usar modelos lineales con variables categ贸ricas. Para KNN, la estandarizaci贸n es fundamental porque el algoritmo depende de distancias.

-Ajuste de hiperpar谩metros: La elecci贸n de **weights="distance"** y la m茅trica (Manhattan o Euclidiana, 
=1 o =2) afecta la frontera de decisi贸n. Valores bajos de  generan sobreajuste, mientras que valores muy grandes llevan a subajuste.

-Validez del modelo: Al aplicar correctamente la divisi贸n entre entrenamiento y prueba se evita data leakage. Esto puede reducir un poco las m茅tricas, pero da una mejor estimaci贸n de la capacidad de generalizaci贸n del modelo.







